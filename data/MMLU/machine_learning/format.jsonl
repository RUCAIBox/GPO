{"input": "In Yann LeCun's cake, the cherry on top is\n(A) reinforcement learning\n(B) self-supervised learning\n(C) unsupervised learning\n(D) supervised learning", "output": "(A)"}
{"input": "What is the dimensionality of the null space of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n(A) 0\n(B) 1\n(C) 2\n(D) 3", "output": "(C)"}
{"input": "Statement 1| The L2 penalty in a ridge regression is equivalent to a Laplace prior on the weights. Statement 2| There is at least one set of 4 points in R^3 that can be shattered by the hypothesis set of all 2D planes in R^3.\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True", "output": "(D)"}
{"input": "Statement 1| If there exists a set of k instances that cannot be shattered by H, then VC(H) < k. Statement 2| If two hypothesis classes H1 and H2 satisfy H1 ⊆ H2, then VC(H1) ≤ VC(H2).\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True", "output": "(D)"}
{"input": "The number of test examples needed to get statistically significant results should be _\n(A) Larger if the error rate is larger.\n(B) Larger if the error rate is smaller.\n(C) Smaller if the error rate is smaller.\n(D) It does not matter.", "output": "(B)"}
